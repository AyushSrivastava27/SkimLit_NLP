{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNDc0frYdBPUZfNdxP522NS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushSrivastava27/SkimLit_NLP/blob/main/SkimLit_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data: [*PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071)\n",
        "\n",
        "Model: [*Neural networks for joint sentence classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n"
      ],
      "metadata": {
        "id": "7hMy8JxYtA1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKHCXEt8nVjK",
        "outputId": "6563340f-c37f-43a2-8cb0-dd48148b1f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook Last Run: 2024-02-16 14:12:42.537622\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f\"Notebook Last Run: {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZTraOR_whKU",
        "outputId": "7948ceb8-1996-44f6-d127-71054b54b545"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-067f08c4-1501-a6a3-56c6-e08815d040a3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp1HaUJrwqkN",
        "outputId": "d18c4651-7243-4487-d949-d6e3b43d0945"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 39 (delta 8), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Receiving objects: 100% (39/39), 177.08 MiB | 12.95 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n",
            "Updating files: 100% (13/13), done.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the [README file](https://github.com/Franck-Dernoncourt/pubmed-rct) from the GitHub page, we get the following information:\n",
        "* PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
        "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
        "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n"
      ],
      "metadata": {
        "id": "xFr7cQJUxNAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what files are in PubMed_20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXVJ3-CWw_5o",
        "outputId": "e6120fac-6de2-4668-a8d1-5bc77a7c8938"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got three separate text files:\n",
        "* `train.txt` - training samples.\n",
        "* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n",
        "* `test.txt` - test samples.\n"
      ],
      "metadata": {
        "id": "VnqdS3TXxpau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by using the 20K dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "Cj8TVJKgxpFg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXvwSXFBxjUB",
        "outputId": "94e3833d-9ef7-40ee-aa03-d82ab8c87dbc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess data"
      ],
      "metadata": {
        "id": "271RPJUSyRRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "7A1Jq9rkyKXq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_lines()` which takes the filepath of a text file, opens it, reads each of the lines and returns them."
      ],
      "metadata": {
        "id": "x6ooBH1Dyl4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + \"train.txt\")\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcP6iJSqyfdf",
        "outputId": "f9694f9a-87f0-4533-f57f-758716a3398f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Returning all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n",
        "  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n",
        "  * `\"text\"` - the text of the line in the abstract.\n",
        "  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`)."
      ],
      "metadata": {
        "id": "61Nv8XcInXQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): #check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into seperate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "qaYN00BVy55R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\")\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7QDqwT5qcEH",
        "outputId": "78bb8226-b0b5-4cd5-fdd6-6b6e2d4c9ccc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 744 ms, sys: 107 ms, total: 851 ms\n",
            "Wall time: 1.2 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:14]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHXLT__Xrej_",
        "outputId": "17b80921-44b3-43f1-eef0-f851af71a711"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# turning our list of dictionaries into pandas DataFrame's so to visualize it better\n",
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "CybyI8Uxr5E-",
        "outputId": "cce37530-6eaa-4d0a-b870-0c4ab9ff40ec"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6769d1b5-30fb-4730-b10a-8a7f3ef434b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6769d1b5-30fb-4730-b10a-8a7f3ef434b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6769d1b5-30fb-4730-b10a-8a7f3ef434b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6769d1b5-30fb-4730-b10a-8a7f3ef434b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-398d2879-e0aa-4217-92af-d175cc77f7b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-398d2879-e0aa-4217-92af-d175cc77f7b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-398d2879-e0aa-4217-92af-d175cc77f7b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB-1EQ5FsQqZ",
        "outputId": "5e633c4c-1591-40ba-a2a6-7c738f6a456c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "IgcfkX_rsc48",
        "outputId": "f0c5f786-e237-4faa-aa1b-a3a6fe381308"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks like most of the abstracts are around 7 to 15 sentences in length\n"
      ],
      "metadata": {
        "id": "0DhwfevUskwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Lists of Sentences"
      ],
      "metadata": {
        "id": "Dp2gyKQGsw4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V90WZ_Jvsh59",
        "outputId": "b2b4d125-4ba0-4f67-dbf8-dd177b8e513d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz1wyQKutJkL",
        "outputId": "90eb2d27-b42c-4f30-9920-970f4b2e063b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Numeric Labels\n",
        "We're going to create one hot and label encoded lables"
      ],
      "metadata": {
        "id": "MC_zzLcCtm1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output = False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud6OjW62tLxU",
        "outputId": "3a5d75b4-423d-486b-b3b6-f46152b4087f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label Encode Labels"
      ],
      "metadata": {
        "id": "FqcKImIUupph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wadwitLYumZc",
        "outputId": "e1f145dd-f447-4827-9a2c-c7a1e0bdc51e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7nPdF_kvdfj",
        "outputId": "b1729c8d-232a-40b7-c8e3-59928d3a2bed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a searies of Model Experiments"
      ],
      "metadata": {
        "id": "ZhBJfiAxhNu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 0: Getting a Baseline\n",
        "\n",
        "Our first Model we'll be a TF-IDF Multinomial Naive Bayes as recommended by `Scikit-Learn's Machine Learning Map`"
      ],
      "metadata": {
        "id": "ENlRJwwIhTap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tf-idf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X = train_sentences,\n",
        "            y = train_labels_encoded);"
      ],
      "metadata": {
        "id": "xMmLmAV2v-S-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(X = val_sentences,\n",
        "              y = val_labels_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nUglUYsiMHE",
        "outputId": "b336c677-c4c0-4dcd-ce48-ee033d524c74"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZivfjVlwifLd",
        "outputId": "11f505bb-a181-4d59-9aab-0e4856336b10"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "8PbCY0boivHM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                     y_pred = baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ydCehH-i9DS",
        "outputId": "aff7facb-5e7d-407d-f5da-bbf3175f0586"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing our data for deep sequence models"
      ],
      "metadata": {
        "id": "z5oYofc-jJ1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "S-D-HfEwjGuL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each sentences on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len # return average sentence length (in tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9o0EPGMjZrd",
        "outputId": "c9afcbcc-680d-4589-e015-b8760919748f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# what's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins = 7);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "l9i0OziHlP1c",
        "outputId": "95a532f2-3074-4515-84b7-679bfc77e286"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CU8V5VgMla2_",
        "outputId": "6f9582b4-051d-47b8-8d73-2fecc8ce5b5d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Maximum sentence length in the training set\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6FfdTs4niPC",
        "outputId": "298f693e-a5ab-4819-9e4f-6a6a9c465634"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text Vectorizer\n"
      ],
      "metadata": {
        "id": "8PCFiWFGny_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words are in our vocabulary?\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "GQBVva1Tnv1U"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text Vectorizer\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens = max_tokens, # no of words in a vocabulary\n",
        "                                    output_sequence_length = 55) # desired output length of vectorized sequences\n",
        "\n"
      ],
      "metadata": {
        "id": "h5xkPzTxoW5z"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "hu2Xmen8o7jQ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text:{len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n {text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8RWbs5PpqWe",
        "outputId": "da1127bf-35a0-467e-e861-e680d98f622c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "uncontrolled inflammation may result in a significant progression in imt and pwv in patients with as .\n",
            "\n",
            "Length of text:17\n",
            "\n",
            "Vectorized text:\n",
            " [[3042  636   91  692    5    8   37  499    5 4586    3 4143    5   12\n",
            "     7   25    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\")\n",
        "print(f\"Most Common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least Common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqJCY5feqBFs",
        "outputId": "200e6f4a-9c9a-4463-d9fb-05f22296c3cc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most Common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least Common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a9Q3IFCrHY1",
        "outputId": "92641a9f-2290-4e07-a282-c2dc6f1ae415"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create custom text embedding\n"
      ],
      "metadata": {
        "id": "MEIa96yYrlP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim = len(rct_20k_text_vocab), # length of vocabulary\n",
        "                               output_dim = 128,\n",
        "                               mask_zero = True,\n",
        "                               name = \"token_embedding\")\n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n {target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:/n {embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1so555yjrhsy",
        "outputId": "e1bf7f83-15c1-48e4-deba-d7dd097b6c6a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            " uncontrolled inflammation may result in a significant progression in imt and pwv in patients with as .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            " [[3042  636   91  692    5    8   37  499    5 4586    3 4143    5   12\n",
            "     7   25    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:/n [[[ 0.03371112 -0.02924675 -0.01748489 ... -0.00984174  0.02566599\n",
            "    0.02101063]\n",
            "  [ 0.00477456  0.04203607  0.04510937 ...  0.03176833  0.00361233\n",
            "    0.02280283]\n",
            "  [-0.00991644 -0.00337821  0.00522258 ... -0.03286706 -0.04359451\n",
            "   -0.01937445]\n",
            "  ...\n",
            "  [-0.04016213 -0.01720987 -0.01869006 ...  0.04507918  0.02335347\n",
            "    0.02917541]\n",
            "  [-0.04016213 -0.01720987 -0.01869006 ...  0.04507918  0.02335347\n",
            "    0.02917541]\n",
            "  [-0.04016213 -0.01720987 -0.01869006 ...  0.04507918  0.02335347\n",
            "    0.02917541]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Datasets (as fast as possible)"
      ],
      "metadata": {
        "id": "5YiCCCRSKAAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i19Q7gVAJ9JC",
        "outputId": "34397764-ff32-4ce4-ca41-62d3858f7ec5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetch batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHQa-CRtKyzD",
        "outputId": "a09ff6e8-0b21-4353-8348-28da085c95a3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Model 1: Conv1D with Token Embeddings\n"
      ],
      "metadata": {
        "id": "4Wakn2iJLT2B"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embeddings\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "E4ohF_xqLbAD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get summary of Conv1D model\n",
        "model_1.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cW5S10rNzdt",
        "outputId": "52aad85b-1ddc-4a85-df5d-b2ca89442c60"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVe  (None, 55)                0         \n",
            " ctorization)                                                    \n",
            "                                                                 \n",
            " token_embedding (Embedding  (None, 55, 128)           8299648   \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 64)                0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8340997 (31.82 MB)\n",
            "Trainable params: 8340997 (31.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch = int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs = 3,\n",
        "                              validation_data = valid_dataset,\n",
        "                              validation_steps = int(0.1 * len(valid_dataset))) # only validate on 10% of batches\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HWRjDFVN454",
        "outputId": "64ca5aa1-e6c0-40d3-b58a-9a423d41f3ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 24s 35ms/step - loss: 0.9196 - accuracy: 0.6344 - val_loss: 0.6879 - val_accuracy: 0.7350\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.6575 - accuracy: 0.7558 - val_loss: 0.6335 - val_accuracy: 0.7699\n",
            "Epoch 3/3\n",
            "313/562 [===============>..............] - ETA: 1s - loss: 0.6161 - accuracy: 0.7745"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "lJWQOblNOl87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (our model outputs prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "metadata": {
        "id": "Yq3f35cBOql5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "metadata": {
        "id": "zp0Jtiw3OtHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "YIFJBAFEOunf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 2: Feature Extraction with pretrained token Embeddings\n",
        "\n",
        "We're using pretrained Universal Sentence Encoder embeddings from TensorFlow Hub"
      ],
      "metadata": {
        "id": "hw70lV2PbruJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable = False,\n",
        "                                        name = \"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "1ixJaVMCOybA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random Training Sentence:\\n {random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence After Embedding:\\n{use_embedded_sentence[0][:30]} (truncated output) ... \\n\")\n",
        "print(f\"Length of Sentence Embedding:\\n {len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "id": "Xf4-KKJncXe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building and fitting an NLP feature Extraction Model from TensorFlow Hub"
      ],
      "metadata": {
        "id": "eJWzRtzydcZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype= tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation = \"relu\")(pretrained_embedding)\n",
        "outputs = layers.Dense(5, activation= \"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs= inputs,\n",
        "                         outputs= outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "5i0morITdVYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "YvVyF0TReww-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit feature extractor model for 3 epochs\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch = int(0.1 * len(train_dataset)),\n",
        "            epochs = 3,\n",
        "            validation_data = valid_dataset,\n",
        "            validation_steps = int(0.1 * len(valid_dataset)))"
      ],
      "metadata": {
        "id": "K1sQ8E31e2Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "JwjDdXUKxPTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "metadata": {
        "id": "PruPVrm9xS2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the predictions with feature extraction model to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "metadata": {
        "id": "Osrbq2PrxcG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
        "\n",
        "model_2_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                    y_pred = model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "Jp5JO5KMxmu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 3: Conv1D with Character Embeddings\n",
        "\n",
        "**Creating a character-level tokenizer**"
      ],
      "metadata": {
        "id": "NCISducpx6th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "metadata": {
        "id": "1Ws6fg4MyGwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "metadata": {
        "id": "5YUbKFcUybNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "SCGFaX2ny4By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of our sequences at character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "id": "2O6EDbTfzFqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "_HguRUTbzRib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all keyboard characters for char-level embedding\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "id": "xvouQQOSzhOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens = NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length = output_seq_char_len,\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    name = \"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "LxJXUkGmzvMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "p6ox1JXB0kb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\n Length of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\n Vectorized chars:\\n {vectorized_chars}\")\n",
        "print(f\"\\n Length of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "id": "PRSBKnXQ1DbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a character-level embeddings"
      ],
      "metadata": {
        "id": "5Cu-lw-T21UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "id": "6_k9_KM4xC5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a Conv1D model to fit on character embeddings"
      ],
      "metadata": {
        "id": "qS38Mwfnxj5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs = inputs,\n",
        "                         outputs = outputs,\n",
        "                         name = \"model_3_conv1D_char_embeddings\")\n",
        "\n",
        "# Compile Model\n",
        "model_3.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "-VXP6Vz7xLs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "id": "qGvTH8iIxxje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "id": "a5NcZvnryzXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "metadata": {
        "id": "KJSU1ptUy2Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model_3 on whole validation char dataset\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "metadata": {
        "id": "IeYos1e_y4hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with character model only\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "id": "ffUCau_Ky7IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert predictions to classes\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "id": "K3HjLxANy9QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Conv1D char only model results\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "fkJZ1h4Dy_pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)"
      ],
      "metadata": {
        "id": "hkIKD1MJzC7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")"
      ],
      "metadata": {
        "id": "JZIANe4jzMFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "id": "JXCcF8BkmevB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot hybrid token and character model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_4)"
      ],
      "metadata": {
        "id": "bIivQ7FtmhXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token char model\n",
        "model_4.compile(loss = \"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "LnQBDBjemtbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine chars and tokens into a dataset\n"
      ],
      "metadata": {
        "id": "GUvoCYPZnNsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "uddKuf1snMIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_token_dataset, val_char_token_dataset"
      ],
      "metadata": {
        "id": "H088RGqPnVU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fitting a model on token and character-level sequences\n"
      ],
      "metadata": {
        "id": "RZpqz996nadQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_history = model_4.fit(train_char_token_dataset,\n",
        "                              steps_per_epoch = int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs = 3,\n",
        "                              validation_data = val_char_token_dataset,\n",
        "                              validation_steps = int(0.1 * len(val_char_token_dataset)))"
      ],
      "metadata": {
        "id": "dWpqKFZinfbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "l2Sm4Xr0n6Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "metadata": {
        "id": "eu_9uzL9n_FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_preds = tf.argmax(model_4_pred_probs, axis = 1)\n",
        "model_4_preds"
      ],
      "metadata": {
        "id": "HMDi_303oM7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4K_results = calculate_results(y_true = val_labels_encoded,\n",
        "                                     y_pred = model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "WwPLJ_jXoid-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings"
      ],
      "metadata": {
        "id": "JIzjByILotkl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "Heo8gs_tosp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Positional Embeddings**"
      ],
      "metadata": {
        "id": "axnmAIM3ESpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many different line numbers are there?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "metadata": {
        "id": "NVN3GwwGEREx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of \"line_number\" column\n",
        "train_df.line_number.plot.hist()"
      ],
      "metadata": {
        "id": "573RYOnFEgKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depths=15)\n",
        "val_line_numbers_one_hot = tf.one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depths = 15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depths = 15)"
      ],
      "metadata": {
        "id": "Bvv5_9tdEpbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking one-hot encoded \"line_number\" feature samples\n",
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
      ],
      "metadata": {
        "id": "wY7yapcMFdip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"total_lines\"].value_counts()"
      ],
      "metadata": {
        "id": "AX_aaSUpFqrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of total lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "YGmvQcIiFxf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.percetile(train_df.total_lines, 98)  # a value of 20 covers 98% of samples"
      ],
      "metadata": {
        "id": "fTCMNP5JF7G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_total_lines_one_hot = tf.one_hot(train_df[\"train_lines\"].to_numpy(), depths = 20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depths = 20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depths = 20)\n",
        "\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
      ],
      "metadata": {
        "id": "H63ufuXcGOuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building a tribid embedding model**"
      ],
      "metadata": {
        "id": "XUa-Ul8qG-RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)"
      ],
      "metadata": {
        "id": "F8Ow1m9LGyW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "id": "TEXRys_TP4wE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_5)"
      ],
      "metadata": {
        "id": "ZIwPowqPQAWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "xCN1WbsLQLwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token, char, positional embedding model\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "SMaG2q4ZQPx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create tribrid embedding datasets and fit tribrid model**"
      ],
      "metadata": {
        "id": "t9YgSElwQXCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
        "                                                                train_total_lines_one_hot, # total lines\n",
        "                                                                train_sentences, # train tokens\n",
        "                                                                train_chars)) # train chars\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ],
      "metadata": {
        "id": "3W36ehnqQYck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "metadata": {
        "id": "nxaY6QZwQa_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with token-char-positional hybrid model\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "id": "vWi_681uQfuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "id": "4-M5wEXZQw_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results of token-char-positional hybrid model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "AN7P1jGPQzWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compare Model Results"
      ],
      "metadata": {
        "id": "pNYySYQ6Q2x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
        "                                  \"pretrained_token_embed\": model_2_results,\n",
        "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
        "                                  \"hybrid_char_token_embed\": model_4_results,\n",
        "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "2CwpXhyAQ8P4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "6EldrQ81Q_Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "id": "E_1So7tlRBor"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}